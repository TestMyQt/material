# 3.06 - Input Handlers

Qt Quick has multiple types that can handle touch events, for example the `MouseArea` we used in the last chapter, `PinchArea`, `MultiPointTouchArea`, and `Flickable`.

These items have some issues. For example, with `MouseArea` Qt assumes there is only one mouse, "core pointer" and `QMouseEvent` and `QTouchEvents` are considered the same events inside Qt Quick. The result is that you cannot interact with two `MouseArea`s or `Flickable`s at the same time. With our previous `MouseArea` usecases this means that you cannot press two `Button`s at the same time or drag two `Slider`s a the same time, for example. This also means that you cannot use `PinchArea` and `MouseArea` together, as when `PinchArea` is active it wont pass the events to the `MouseArea`.

To fix these issues, Qt introduced the new **Input Handler** types. Input Handlers can be declared inside any `Item` type and they can handle events from any pointing devices on behalf of the `parent`. They are very lightweight types, they are intended to be declared as a handler for each interaction type there might exist. Each `Item` can have unlimited `Handler` types, so you wont run out of them.

You can declare constraints on what kind of interaction the handler is going to react on, whether it is a touch event, mouse button or a modifier key is active. This is done with the properties `acceptedButtons` and `acceptedDevices` where one can select the accepted [`Qt::MouseButton`](http://doc.qt.io/qt-5/qt.html#MouseButton-enum)s or the accepted pointer devices like `PointerDevice.Mouse`, `PointerDevice.Stylus` or `PointerDevice.TouchScreen`.

// *J: Remember to change this when Qt 5.12 comes out!*

To use these new experimental handlers, we need to import from `Qt.labs.handlers 1.0`. 

Now, let's go through some of the Input Handlers with examples.

## TapHandler

`TapHandler` is comparable to `MouseArea` with a few key differences:

```qml
import Qt.labs.handlers 1.0

Item {
    TapHandler {
        acceptedDevices: PointerDevice.Mouse | PointerDevice.Stylus
        onTapped: console.log("left clicked")
    }
    
    TapHandler {
        acceptedDevices: PointerDevice.TouchScreen
        onTapped: console.log("tapped")
    }
    
    TapHandler {
        acceptedButtons: Qt.RightButton
        onTapped: console.log("right clicked")
    }
}
```
We can now accept events from specific devices and react accordingly. We can also have multiple `TapHandlers` active inside the same item without issues like with multiple `MouseArea`s.

## DragHandler

`DragHandler` is similar to the `MouseArea`'s `drag` property, but more straightforward to use. It has the similar `xAxis` and `yAxis` [property groups](http://doc-snapshots.qt.io/qt5-5.10/qml-qt-labs-handlers-draghandler.html#xAxis-prop) as the `MouseArea`: 

```qml
import Qt.labs.handlers 1.0

Rectangle {
    width: 50
    height: 50
    color: "green"
    
    DragHandler {
        yAxis.enabled: false
    }
}
```
In the example, the `Rectangle` can be dragger, but only along the X-axis, since we disabled the Y-axis.

## PointHandler

There is also a `PointHandler` which can be used to track a touch point:

```qml
import Qt.labs.handlers 1.0

Item {
    id: root

    PointHandler {
        id: handler
        acceptedDevices: PointerDevice.Mouse |Â PointerDevice.Stylus
        target: Rectangle {
            parent: root
            color: "blue"
            visible: handler.active
            x: handler.point.position.x - width / 2
            y: handler.point.position.y - height / 2
            width: 20
            height: width
            radius: width / 2
        }
    }

}

```

When a press event occurs, the handler will choose a point that has not been bound to any other handlers. It will check if the constraints given (`acceptedDevices` etc.) are satisfied and it is eligible for the point. It will then track the point with the property `active` as `true` until release. Like other handlers, it has the `target` property where we have placed an `Rectangle` and bound the handler properties.

***
